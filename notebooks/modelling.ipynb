{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba5cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df698512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/users/hadiahmed/documents/projects/football-predictor/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63e43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from football_model.data.get_data import get_understat_data\n",
    "from football_model.features.add_metadata import add_rounds_to_data, add_home_away_goals_xg, add_match_ids\n",
    "from football_model.data.prepare_model_data import prepare_model_data\n",
    "from football_model.model.model import build_model\n",
    "from football_model.types.model_data import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:34: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(adjust_round)\n",
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(make_rounds_consecutive)\n"
     ]
    }
   ],
   "source": [
    "## Model is trained on 2024-2025 season data to assess fit (will be deployed on 2025-2026 season data)\n",
    "\n",
    "## Pull in data and prepare model input\n",
    "df = get_understat_data(leagues=['EPL'],years=[str(i) for i in range(2024,2025)])\n",
    "df = add_rounds_to_data(df)\n",
    "df = add_match_ids(df)\n",
    "df = add_home_away_goals_xg(df)\n",
    "input_model_data = prepare_model_data(df,max_round=30)\n",
    "\n",
    "# Create model configuration\n",
    "config = ModelConfig(\n",
    "    clip_theta=5.0,\n",
    "    center_team_strength=False,\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_model_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c52fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>team</th>\n",
       "      <th>opp_team</th>\n",
       "      <th>team_long</th>\n",
       "      <th>opp_team_long</th>\n",
       "      <th>goals</th>\n",
       "      <th>xG</th>\n",
       "      <th>goals_against</th>\n",
       "      <th>xGA</th>\n",
       "      <th>is_home</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>gd</th>\n",
       "      <th>round</th>\n",
       "      <th>cum_round</th>\n",
       "      <th>match_key</th>\n",
       "      <th>match_id</th>\n",
       "      <th>goals_home</th>\n",
       "      <th>xG_home</th>\n",
       "      <th>goals_away</th>\n",
       "      <th>xG_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2025-04-22 19:00:00</td>\n",
       "      <td>AVL</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>1</td>\n",
       "      <td>1.859060</td>\n",
       "      <td>2</td>\n",
       "      <td>1.362320</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-04-22 19:00:00_AVL_MCI</td>\n",
       "      <td>330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.859060</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.362320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2025-04-22 19:00:00</td>\n",
       "      <td>MCI</td>\n",
       "      <td>AVL</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>2</td>\n",
       "      <td>1.362320</td>\n",
       "      <td>1</td>\n",
       "      <td>1.859060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-04-22 19:00:00_AVL_MCI</td>\n",
       "      <td>330</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.362320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.859060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2025-04-23 19:00:00</td>\n",
       "      <td>ARS</td>\n",
       "      <td>CRY</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>2</td>\n",
       "      <td>1.921490</td>\n",
       "      <td>2</td>\n",
       "      <td>2.505150</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-04-23 19:00:00_ARS_CRY</td>\n",
       "      <td>331</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.921490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.505150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2025-04-23 19:00:00</td>\n",
       "      <td>CRY</td>\n",
       "      <td>ARS</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2</td>\n",
       "      <td>2.505150</td>\n",
       "      <td>2</td>\n",
       "      <td>1.921490</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-04-23 19:00:00_ARS_CRY</td>\n",
       "      <td>331</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.505150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.921490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2025-04-26 11:30:00</td>\n",
       "      <td>CHE</td>\n",
       "      <td>EVE</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Everton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768313</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916838</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-04-26 11:30:00_CHE_EVE</td>\n",
       "      <td>332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.768313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2025-05-25 15:00:00</td>\n",
       "      <td>AVL</td>\n",
       "      <td>MUN</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335222</td>\n",
       "      <td>2</td>\n",
       "      <td>2.962590</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>-2</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-05-25 15:00:00_AVL_MUN</td>\n",
       "      <td>371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.962590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>2025-05-25 15:00:00</td>\n",
       "      <td>EVE</td>\n",
       "      <td>NEW</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>1</td>\n",
       "      <td>1.072790</td>\n",
       "      <td>0</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-05-25 15:00:00_EVE_NEW</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.072790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2025-05-25 15:00:00</td>\n",
       "      <td>CHE</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Nottingham Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1.308740</td>\n",
       "      <td>0</td>\n",
       "      <td>1.580140</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-05-25 15:00:00_CHE_NOT</td>\n",
       "      <td>375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.580140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2025-05-25 15:00:00</td>\n",
       "      <td>FLH</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>0</td>\n",
       "      <td>2.217970</td>\n",
       "      <td>2</td>\n",
       "      <td>2.459230</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>-2</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-05-25 15:00:00_FLH_MCI</td>\n",
       "      <td>378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.217970</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.459230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2025-05-25 15:00:00</td>\n",
       "      <td>MCI</td>\n",
       "      <td>FLH</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>2</td>\n",
       "      <td>2.459230</td>\n",
       "      <td>0</td>\n",
       "      <td>2.217970</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-05-25 15:00:00_FLH_MCI</td>\n",
       "      <td>378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.459230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.217970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime team opp_team        team_long      opp_team_long  \\\n",
       "660 2025-04-22 19:00:00  AVL      MCI      Aston Villa    Manchester City   \n",
       "661 2025-04-22 19:00:00  MCI      AVL  Manchester City        Aston Villa   \n",
       "662 2025-04-23 19:00:00  ARS      CRY          Arsenal     Crystal Palace   \n",
       "663 2025-04-23 19:00:00  CRY      ARS   Crystal Palace            Arsenal   \n",
       "664 2025-04-26 11:30:00  CHE      EVE          Chelsea            Everton   \n",
       "..                  ...  ...      ...              ...                ...   \n",
       "742 2025-05-25 15:00:00  AVL      MUN      Aston Villa  Manchester United   \n",
       "741 2025-05-25 15:00:00  EVE      NEW          Everton   Newcastle United   \n",
       "740 2025-05-25 15:00:00  CHE      NOT          Chelsea  Nottingham Forest   \n",
       "748 2025-05-25 15:00:00  FLH      MCI           Fulham    Manchester City   \n",
       "759 2025-05-25 15:00:00  MCI      FLH  Manchester City             Fulham   \n",
       "\n",
       "     goals        xG  goals_against       xGA  is_home  ...  season  gd  \\\n",
       "660      1  1.859060              2  1.362320        0  ...    2024  -1   \n",
       "661      2  1.362320              1  1.859060        1  ...    2024   1   \n",
       "662      2  1.921490              2  2.505150        1  ...    2024   0   \n",
       "663      2  2.505150              2  1.921490        0  ...    2024   0   \n",
       "664      1  0.768313              0  0.916838        1  ...    2024   1   \n",
       "..     ...       ...            ...       ...      ...  ...     ...  ..   \n",
       "742      0  0.335222              2  2.962590        0  ...    2024  -2   \n",
       "741      1  1.072790              0  1.159100        0  ...    2024   1   \n",
       "740      1  1.308740              0  1.580140        0  ...    2024   1   \n",
       "748      0  2.217970              2  2.459230        1  ...    2024  -2   \n",
       "759      2  2.459230              0  2.217970        0  ...    2024   2   \n",
       "\n",
       "     round cum_round                    match_key  match_id  goals_home  \\\n",
       "660     30        30  2025-04-22 19:00:00_AVL_MCI       330         1.0   \n",
       "661     30        30  2025-04-22 19:00:00_AVL_MCI       330         2.0   \n",
       "662     30        30  2025-04-23 19:00:00_ARS_CRY       331         2.0   \n",
       "663     30        30  2025-04-23 19:00:00_ARS_CRY       331         2.0   \n",
       "664     30        30  2025-04-26 11:30:00_CHE_EVE       332         1.0   \n",
       "..     ...       ...                          ...       ...         ...   \n",
       "742     34        34  2025-05-25 15:00:00_AVL_MUN       371         0.0   \n",
       "741     34        34  2025-05-25 15:00:00_EVE_NEW       377         1.0   \n",
       "740     34        34  2025-05-25 15:00:00_CHE_NOT       375         1.0   \n",
       "748     34        34  2025-05-25 15:00:00_FLH_MCI       378         0.0   \n",
       "759     34        34  2025-05-25 15:00:00_FLH_MCI       378         2.0   \n",
       "\n",
       "      xG_home  goals_away   xG_away  \n",
       "660  1.859060         2.0  1.362320  \n",
       "661  1.362320         1.0  1.859060  \n",
       "662  1.921490         2.0  2.505150  \n",
       "663  2.505150         2.0  1.921490  \n",
       "664  0.768313         0.0  0.916838  \n",
       "..        ...         ...       ...  \n",
       "742  0.335222         2.0  2.962590  \n",
       "741  1.072790         0.0  1.159100  \n",
       "740  1.308740         0.0  1.580140  \n",
       "748  2.217970         2.0  2.459230  \n",
       "759  2.459230         0.0  2.217970  \n",
       "\n",
       "[100 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df[df['round']>=30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417de780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "            \\begin{array}{rcl}\n",
       "            \\text{sigma\\_att} &\\sim & \\operatorname{HalfNormal}(0,~0.008)\\\\\\text{rho\\_att} &\\sim & \\operatorname{Beta}(29,~1)\\\\\\text{sigma\\_def} &\\sim & \\operatorname{HalfNormal}(0,~0.008)\\\\\\text{rho\\_def} &\\sim & \\operatorname{Beta}(29,~1)\\\\\\text{att\\_0} &\\sim & \\operatorname{Normal}(0,~0.2)\\\\\\text{def\\_0} &\\sim & \\operatorname{Normal}(0,~0.2)\\\\\\text{att\\_rw\\_std} &\\sim & \\operatorname{Normal}(0,~1)\\\\\\text{def\\_rw\\_std} &\\sim & \\operatorname{Normal}(0,~1)\\\\\\text{home\\_mu} &\\sim & \\operatorname{Normal}(0.13,~0.03)\\\\\\text{home\\_sd} &\\sim & \\operatorname{HalfNormal}(0,~0.02)\\\\\\text{home\\_adv} &\\sim & \\operatorname{Normal}(\\text{home\\_mu},~\\text{home\\_sd})\\\\\\text{att\\_rw} &\\sim & \\operatorname{Deterministic}(f(\\text{sigma\\_att},~\\text{rho\\_att},~\\text{att\\_rw\\_std}))\\\\\\text{def\\_rw} &\\sim & \\operatorname{Deterministic}(f(\\text{sigma\\_def},~\\text{rho\\_def},~\\text{def\\_rw\\_std}))\\\\\\text{attack} &\\sim & \\operatorname{Deterministic}(f(\\text{att\\_0},~\\text{sigma\\_att},~\\text{rho\\_att},~\\text{att\\_rw\\_std}))\\\\\\text{defence} &\\sim & \\operatorname{Deterministic}(f(\\text{def\\_0},~\\text{sigma\\_def},~\\text{rho\\_def},~\\text{def\\_rw\\_std}))\\\\\\text{lambda\\_home} &\\sim & \\operatorname{Deterministic}(f(\\text{home\\_adv},~\\text{def\\_0},~\\text{att\\_0},~\\text{sigma\\_def},~\\text{rho\\_def},~\\text{def\\_rw\\_std},~\\text{sigma\\_att},~\\text{rho\\_att},~\\text{att\\_rw\\_std}))\\\\\\text{lambda\\_away} &\\sim & \\operatorname{Deterministic}(f(\\text{def\\_0},~\\text{att\\_0},~\\text{sigma\\_def},~\\text{rho\\_def},~\\text{def\\_rw\\_std},~\\text{sigma\\_att},~\\text{rho\\_att},~\\text{att\\_rw\\_std}))\\\\\\text{goals\\_home} &\\sim & \\operatorname{Poisson}(\\text{lambda\\_home})\\\\\\text{goals\\_away} &\\sim & \\operatorname{Poisson}(\\text{lambda\\_away})\n",
       "            \\end{array}\n",
       "            $$"
      ],
      "text/plain": [
       "  sigma_att ~ HalfNormal(0, 0.008)\n",
       "    rho_att ~ Beta(29, 1)\n",
       "  sigma_def ~ HalfNormal(0, 0.008)\n",
       "    rho_def ~ Beta(29, 1)\n",
       "      att_0 ~ Normal(0, 0.2)\n",
       "      def_0 ~ Normal(0, 0.2)\n",
       " att_rw_std ~ Normal(0, 1)\n",
       " def_rw_std ~ Normal(0, 1)\n",
       "    home_mu ~ Normal(0.13, 0.03)\n",
       "    home_sd ~ HalfNormal(0, 0.02)\n",
       "   home_adv ~ Normal(home_mu, home_sd)\n",
       "     att_rw ~ Deterministic(f(sigma_att, rho_att, att_rw_std))\n",
       "     def_rw ~ Deterministic(f(sigma_def, rho_def, def_rw_std))\n",
       "     attack ~ Deterministic(f(att_0, sigma_att, rho_att, att_rw_std))\n",
       "    defence ~ Deterministic(f(def_0, sigma_def, rho_def, def_rw_std))\n",
       "lambda_home ~ Deterministic(f(home_adv, def_0, att_0, sigma_def, rho_def, def_rw_std, sigma_att, rho_att, att_rw_std))\n",
       "lambda_away ~ Deterministic(f(def_0, att_0, sigma_def, rho_def, def_rw_std, sigma_att, rho_att, att_rw_std))\n",
       " goals_home ~ Poisson(lambda_home)\n",
       " goals_away ~ Poisson(lambda_away)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inspect model parameters\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0829dc71e0848749fc7951f1562f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 5_000 draw iterations (8_000 + 20_000 draws total) took 727 seconds.\n",
      "There were 734 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "\n",
    "# Sample from the posterior with better settings to handle divergences\n",
    "# Increased for 2-season model (67 time steps = more parameters)\n",
    "with model:\n",
    "    trace = pm.sample(\n",
    "        5000,  \n",
    "        tune=2000,  \n",
    "        chains=4,  \n",
    "        target_accept=0.97,  \n",
    "        random_seed=42,\n",
    "        idata_kwargs={\"log_likelihood\": True},\n",
    "        return_inferencedata=True,\n",
    "        discard_tuned_samples=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85af65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [mean, sd, hdi_3%, hdi_97%, mcse_mean, mcse_sd, ess_bulk, ess_tail, r_hat]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check convergence diagnostics\n",
    "import arviz as az\n",
    "\n",
    "# Summary statistics and convergence diagnostics\n",
    "summary = az.summary(trace, round_to=3)\n",
    "print(summary[summary['r_hat'] > 1.01])  # Show problematic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69d36413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acceptance rate: 0.935 (target: 0.95)\n",
      "\n",
      "Step size per chain: [0.05888671 0.07735848 0.0696604  0.03869496]\n",
      "\n",
      "Total divergences: 524\n"
     ]
    }
   ],
   "source": [
    "# Check if tuning was sufficient by looking at acceptance rates and step sizes\n",
    "import arviz as az\n",
    "\n",
    "# Sample stats tell you about the sampler behavior\n",
    "sample_stats = trace.sample_stats\n",
    "\n",
    "# Check final acceptance rates (should be close to target_accept=0.95)\n",
    "acceptance_rate = sample_stats.acceptance_rate.mean().values\n",
    "print(f\"Mean acceptance rate: {acceptance_rate:.3f} (target: 0.95)\")\n",
    "\n",
    "# Check step sizes stabilized (look at the last tune iterations)\n",
    "print(f\"\\nStep size per chain: {sample_stats.step_size.isel(draw=-1).values}\")\n",
    "\n",
    "# Check divergences\n",
    "n_divergences = sample_stats.diverging.sum().values\n",
    "print(f\"\\nTotal divergences: {n_divergences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8548432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [goals_away, goals_home]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c116ca3631144bbaab0055854c9bb57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample from the posterior predictive distribution\n",
    "with model:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff2367",
   "metadata": {},
   "source": [
    "## In Sample MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Home Goals): 0.874\n",
      "MAE (Away Goals): 0.866\n",
      "Overall MAE: 0.870\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate prediction metrics\n",
    "import numpy as np\n",
    "\n",
    "# Get mean predictions\n",
    "goals_home_pred = posterior_predictive.posterior_predictive['goals_home'].mean(dim=['chain', 'draw']).values\n",
    "goals_away_pred = posterior_predictive.posterior_predictive['goals_away'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Calculate MAE\n",
    "mae_home = np.mean(np.abs(goals_home_pred - input_model_data.goals_home))\n",
    "mae_away = np.mean(np.abs(goals_away_pred - input_model_data.goals_away))\n",
    "\n",
    "print(f\"MAE (Home Goals): {mae_home:.3f}\")\n",
    "print(f\"MAE (Away Goals): {mae_away:.3f}\")\n",
    "print(f\"Overall MAE: {(mae_home + mae_away)/2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442da19b",
   "metadata": {},
   "source": [
    "## OOS Performance MAE (on 2 gameweeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daec7c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 678 matches (rounds 1-30)\n",
      "Test data: 50 matches (rounds 31+)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on OUT-OF-SAMPLE test data (rounds 33+)\n",
    "# Prepare test data\n",
    "test_data = prepare_model_data(df, test_round=100)  # Use all available data\n",
    "\n",
    "# Get test indices (only rounds > 0)\n",
    "test_mask = df['cum_round'] > 29\n",
    "test_df = df[test_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training data: {len(input_model_data.goals_home)} matches (rounds 1-{test_df['round'].min()})\")\n",
    "print(f\"Test data: {len(test_df)//2} matches (rounds {test_df['round'].min()+1}+)\")  # Divide by 2 because each match is 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0 means full trust in xG, <1.0 means down-weighted)\n",
      "\n",
      "=== OUT-OF-SAMPLE PERFORMANCE ===\n",
      "OOS MAE (Home Goals): 1.286\n",
      "OOS MAE (Away Goals): 1.173\n",
      "OOS Overall MAE: 1.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:34: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(adjust_round)\n",
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(make_rounds_consecutive)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Make predictions on test data using the trained model\n",
    "# First, prepare the full dataset to get team_id mappings\n",
    "df_full = get_understat_data(leagues=['EPL'],years=['2024'])\n",
    "df_full = add_rounds_to_data(df_full)\n",
    "df_full = add_match_ids(df_full)\n",
    "df_full = add_home_away_goals_xg(df_full)\n",
    "\n",
    "# Add team_id mappings (same as in prepare_model_data)\n",
    "teams = pd.unique(df_full[['team', 'opp_team']].values.ravel())\n",
    "team_idx_map = {t: i for i, t in enumerate(teams)}\n",
    "df_full[\"team_id\"] = df_full[\"team\"].map(team_idx_map)\n",
    "df_full[\"opp_id\"] = df_full[\"opp_team\"].map(team_idx_map)\n",
    "\n",
    "# Extract test data indices\n",
    "test_mask = (df_full['cum_round'] > 29).values\n",
    "test_indices = np.where(test_mask)[0]\n",
    "\n",
    "# Get posterior means from the trained model\n",
    "attack_mean = trace.posterior['attack'].mean(dim=['chain', 'draw']).values\n",
    "defense_mean = trace.posterior['defence'].mean(dim=['chain', 'draw']).values\n",
    "home_adv_mean = trace.posterior['home_adv'].mean(dim=['chain', 'draw']).values\n",
    "# beta_xG_mean = trace.posterior['beta_xG'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# print(f\"Learned beta_xG weight: {beta_xG_mean:.3f}\")\n",
    "print(f\"(1.0 means full trust in xG, <1.0 means down-weighted)\")\n",
    "\n",
    "# Build predictions for test set\n",
    "last_t = attack_mean.shape[0] - 1\n",
    "\n",
    "test_lambda_home = []\n",
    "test_lambda_away = []\n",
    "\n",
    "for idx in test_indices:\n",
    "    team_id = int(df_full.iloc[idx]['team_id'])\n",
    "    opp_id = int(df_full.iloc[idx]['opp_id'])\n",
    "    is_home = df_full.iloc[idx]['is_home']\n",
    "    xG_home = df_full.iloc[idx]['xG_home']\n",
    "    xG_away = df_full.iloc[idx]['xG_away']\n",
    "    \n",
    "    # Use weighted xG baseline\n",
    "    theta_home = np.log(xG_home + 0.01) + attack_mean[last_t, team_id] - defense_mean[last_t, opp_id]\n",
    "    if is_home == 1:\n",
    "        theta_home += home_adv_mean[team_id]\n",
    "    \n",
    "    theta_away = np.log(xG_away + 0.01) + attack_mean[last_t, opp_id] - defense_mean[last_t, team_id]\n",
    "    \n",
    "    test_lambda_home.append(np.exp(np.clip(theta_home, -5, 5)))\n",
    "    test_lambda_away.append(np.exp(np.clip(theta_away, -5, 5)))\n",
    "\n",
    "test_lambda_home = np.array(test_lambda_home)\n",
    "test_lambda_away = np.array(test_lambda_away)\n",
    "\n",
    "# Get actual test goals\n",
    "test_goals_home = df_full[test_mask]['goals_home'].values\n",
    "test_goals_away = df_full[test_mask]['goals_away'].values\n",
    "\n",
    "# Calculate OOS MAE\n",
    "oos_mae_home = np.mean(np.abs(test_lambda_home - test_goals_home))\n",
    "oos_mae_away = np.mean(np.abs(test_lambda_away - test_goals_away))\n",
    "\n",
    "print(f\"\\n=== OUT-OF-SAMPLE PERFORMANCE ===\")\n",
    "print(f\"OOS MAE (Home Goals): {oos_mae_home:.3f}\")\n",
    "print(f\"OOS MAE (Away Goals): {oos_mae_away:.3f}\")\n",
    "print(f\"OOS Overall MAE: {(oos_mae_home + oos_mae_away)/2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab693",
   "metadata": {},
   "source": [
    "## OOS Log Likelihood metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ed379a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUT-OF-SAMPLE LOG LIKELIHOOD ===\n",
      "Our Model Total LL: -262.51\n",
      "Our Model LL per goal: -1.601\n",
      "\n",
      "Naive Baseline (historical avg) Total LL: -236.10\n",
      "Naive Baseline LL per goal: -1.440\n",
      "\n",
      "Simple Team Averages Total LL: -233.68\n",
      "Simple Team Averages LL per goal: -1.425\n",
      "\n",
      "=== IMPROVEMENTS OVER BASELINES ===\n",
      "vs Naive: -26.41 total LL improvement\n",
      "vs Simple Team Avg: -28.83 total LL improvement\n",
      "\n",
      "Bayes Factor vs Naive: 3.38e-12\n",
      "Bayes Factor vs Simple: 3.01e-13\n"
     ]
    }
   ],
   "source": [
    "# Calculate log likelihood for OOS predictions\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Our model predictions (using Poisson now)\n",
    "model_ll_home = poisson.logpmf(test_goals_home.astype(int), test_lambda_home).sum()\n",
    "model_ll_away = poisson.logpmf(test_goals_away.astype(int), test_lambda_away).sum()\n",
    "model_ll_total = model_ll_home + model_ll_away\n",
    "model_ll_per_goal = model_ll_total / (len(test_goals_home) + len(test_goals_away))\n",
    "\n",
    "print(f\"\\n=== OUT-OF-SAMPLE LOG LIKELIHOOD ===\")\n",
    "print(f\"Our Model Total LL: {model_ll_total:.2f}\")\n",
    "print(f\"Our Model LL per goal: {model_ll_per_goal:.3f}\")\n",
    "\n",
    "# Benchmark 1: Poisson with historical average (naive baseline)\n",
    "historical_avg_home = df_full[df_full['cum_round'] <= 32]['goals_home'].mean()\n",
    "historical_avg_away = df_full[df_full['cum_round'] <= 32]['goals_away'].mean()\n",
    "\n",
    "naive_ll_home = poisson.logpmf(test_goals_home.astype(int), historical_avg_home).sum()\n",
    "naive_ll_away = poisson.logpmf(test_goals_away.astype(int), historical_avg_away).sum()\n",
    "naive_ll_total = naive_ll_home + naive_ll_away\n",
    "naive_ll_per_goal = naive_ll_total / (len(test_goals_home) + len(test_goals_away))\n",
    "\n",
    "print(f\"\\nNaive Baseline (historical avg) Total LL: {naive_ll_total:.2f}\")\n",
    "print(f\"Naive Baseline LL per goal: {naive_ll_per_goal:.3f}\")\n",
    "\n",
    "# Benchmark 2: Team-specific averages (no time dynamics, no home advantage)\n",
    "team_goals_scored = df_full[df_full['cum_round'] <= 32].groupby('team_id')['goals_home'].mean()\n",
    "team_goals_conceded = df_full[df_full['cum_round'] <= 32].groupby('team_id')['goals_away'].mean()\n",
    "\n",
    "simple_ll_home = []\n",
    "simple_ll_away = []\n",
    "\n",
    "for idx in test_indices:\n",
    "    team_id = int(df_full.iloc[idx]['team_id'])\n",
    "    opp_id = int(df_full.iloc[idx]['opp_id'])\n",
    "    \n",
    "    # Simple prediction: team's avg scored vs opp's avg conceded\n",
    "    lambda_h = (team_goals_scored.get(team_id, historical_avg_home) + \n",
    "                team_goals_conceded.get(opp_id, historical_avg_away)) / 2\n",
    "    lambda_a = (team_goals_scored.get(opp_id, historical_avg_away) + \n",
    "                team_goals_conceded.get(team_id, historical_avg_home)) / 2\n",
    "    \n",
    "    simple_ll_home.append(poisson.logpmf(int(df_full.iloc[idx]['goals_home']), lambda_h))\n",
    "    simple_ll_away.append(poisson.logpmf(int(df_full.iloc[idx]['goals_away']), lambda_a))\n",
    "\n",
    "simple_ll_total = np.sum(simple_ll_home) + np.sum(simple_ll_away)\n",
    "simple_ll_per_goal = simple_ll_total / (len(test_goals_home) + len(test_goals_away))\n",
    "\n",
    "print(f\"\\nSimple Team Averages Total LL: {simple_ll_total:.2f}\")\n",
    "print(f\"Simple Team Averages LL per goal: {simple_ll_per_goal:.3f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "print(f\"\\n=== IMPROVEMENTS OVER BASELINES ===\")\n",
    "print(f\"vs Naive: {model_ll_total - naive_ll_total:.2f} total LL improvement\")\n",
    "print(f\"vs Simple Team Avg: {model_ll_total - simple_ll_total:.2f} total LL improvement\")\n",
    "print(f\"\\nBayes Factor vs Naive: {np.exp(model_ll_total - naive_ll_total):.2e}\")\n",
    "print(f\"Bayes Factor vs Simple: {np.exp(model_ll_total - simple_ll_total):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9506773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing likelihood functions ===\n",
      "\n",
      "Our Model with Poisson LL: -262.51\n",
      "Our Model with NegBin LL: -262.51\n",
      "Naive Baseline (Poisson): -236.10\n",
      "Simple Team Avg (Poisson): -233.68\n",
      "\n",
      "=== FAIR COMPARISON (all using Poisson) ===\n",
      "Our Model vs Naive: -26.41 LL improvement\n",
      "Our Model vs Simple: -28.83 LL improvement\n",
      "\n",
      "Bayes Factor vs Naive: 3.38e-12\n",
      "Bayes Factor vs Simple: 3.01e-13\n",
      "\n",
      "=== Lambda Statistics ===\n",
      "Our model - Home lambda mean: 0.635, std: 0.357\n",
      "Our model - Away lambda mean: 0.590, std: 0.324\n",
      "Naive baseline - Home: 1.472, Away: 1.472\n",
      "\n",
      "Actual test data - Home mean: 1.305, Away mean: 1.305\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check alpha value and compare Poisson vs NB\n",
    "# print(f\"Alpha (dispersion) mean: {alpha_mean:.4f}\")\n",
    "# print(f\"This means variance = mean * (1 + alpha * mean)\")\n",
    "\n",
    "# Compare our NB predictions vs simple Poisson on same lambdas\n",
    "print(\"\\n=== Comparing likelihood functions ===\")\n",
    "\n",
    "# Use Poisson instead of NB for fair comparison with baselines\n",
    "model_poisson_ll_home = poisson.logpmf(test_goals_home.astype(int), test_lambda_home).sum()\n",
    "model_poisson_ll_away = poisson.logpmf(test_goals_away.astype(int), test_lambda_away).sum()\n",
    "model_poisson_total = model_poisson_ll_home + model_poisson_ll_away\n",
    "\n",
    "print(f\"\\nOur Model with Poisson LL: {model_poisson_total:.2f}\")\n",
    "print(f\"Our Model with NegBin LL: {model_ll_total:.2f}\")\n",
    "print(f\"Naive Baseline (Poisson): {naive_ll_total:.2f}\")\n",
    "print(f\"Simple Team Avg (Poisson): {simple_ll_total:.2f}\")\n",
    "\n",
    "print(f\"\\n=== FAIR COMPARISON (all using Poisson) ===\")\n",
    "print(f\"Our Model vs Naive: {model_poisson_total - naive_ll_total:.2f} LL improvement\")\n",
    "print(f\"Our Model vs Simple: {model_poisson_total - simple_ll_total:.2f} LL improvement\")\n",
    "print(f\"\\nBayes Factor vs Naive: {np.exp(model_poisson_total - naive_ll_total):.2e}\")\n",
    "print(f\"Bayes Factor vs Simple: {np.exp(model_poisson_total - simple_ll_total):.2e}\")\n",
    "\n",
    "# Show why our lambdas might be worse\n",
    "print(f\"\\n=== Lambda Statistics ===\")\n",
    "print(f\"Our model - Home lambda mean: {test_lambda_home.mean():.3f}, std: {test_lambda_home.std():.3f}\")\n",
    "print(f\"Our model - Away lambda mean: {test_lambda_away.mean():.3f}, std: {test_lambda_away.std():.3f}\")\n",
    "print(f\"Naive baseline - Home: {historical_avg_home:.3f}, Away: {historical_avg_away:.3f}\")\n",
    "print(f\"\\nActual test data - Home mean: {test_goals_home.mean():.3f}, Away mean: {test_goals_away.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b76f127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 20 R-hat values:\n",
      "                     mean     sd  r_hat\n",
      "home_sd             0.017  0.012  1.011\n",
      "def_rw_std[30, 7]   0.050  1.039  1.005\n",
      "att_rw_std[2, 17]   0.337  0.970  1.004\n",
      "att_rw_std[3, 17]   0.384  0.990  1.004\n",
      "att_rw_std[6, 9]   -0.114  1.006  1.004\n",
      "att_rw_std[10, 6]  -0.512  0.996  1.004\n",
      "att_rw_std[12, 5]   0.205  0.992  1.004\n",
      "att_rw_std[21, 15] -0.607  0.997  1.004\n",
      "def_rw_std[2, 15]  -0.069  1.045  1.004\n",
      "att_0[7]            0.076  0.176  1.003\n",
      "att_rw_std[1, 19]  -0.136  1.008  1.003\n",
      "att_rw_std[8, 2]    0.321  0.987  1.003\n",
      "att_rw_std[9, 2]    0.290  0.986  1.003\n",
      "att_rw_std[9, 4]   -0.136  0.981  1.003\n",
      "att_rw_std[17, 15] -0.444  0.981  1.003\n",
      "att_rw_std[19, 5]  -0.761  1.025  1.003\n",
      "att_rw_std[21, 3]  -0.977  0.994  1.003\n",
      "att_rw_std[26, 5]  -0.648  1.012  1.003\n",
      "att_rw_std[27, 10] -0.578  0.997  1.003\n",
      "att_rw_std[30, 19] -0.204  0.985  1.003\n",
      "\n",
      "=== R-hat by parameter type ===\n",
      "attack: 0/660 with r_hat > 1.01\n",
      "home_adv: 0/20 with r_hat > 1.01\n",
      "rho: 0/2 with r_hat > 1.01\n",
      "sigma: 0/2 with r_hat > 1.01\n"
     ]
    }
   ],
   "source": [
    "# Check which parameters have worst convergence\n",
    "import pandas as pd\n",
    "\n",
    "worst_rhat = summary.nlargest(20, 'r_hat')[['mean', 'sd', 'r_hat']]\n",
    "print(\"Worst 20 R-hat values:\")\n",
    "print(worst_rhat)\n",
    "\n",
    "# Check if it's specific to certain parameter types\n",
    "print(\"\\n=== R-hat by parameter type ===\")\n",
    "for param_type in ['attack', 'defense', 'home_adv', 'match_effect', 'rho', 'sigma']:\n",
    "    param_mask = summary.index.str.contains(param_type)\n",
    "    if param_mask.any():\n",
    "        bad_count = (summary.loc[param_mask, 'r_hat'] > 1.01).sum()\n",
    "        total_count = param_mask.sum()\n",
    "        print(f\"{param_type}: {bad_count}/{total_count} with r_hat > 1.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "593103d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERGENCE SUMMARY ===\n",
      "Total parameters with R-hat > 1.01: 722/5143\n",
      "Total parameters with R-hat > 1.05: 0/5143\n",
      "\n",
      "Worst R-hat values:\n",
      "                     mean     sd  r_hat\n",
      "def_rw_std[9, 1]    0.130  1.144  1.040\n",
      "att_rw_std[5, 18]   0.058  1.235  1.032\n",
      "def_rw_std[1, 2]   -0.106  1.095  1.031\n",
      "att_rw_std[6, 14]   0.168  1.160  1.029\n",
      "def_rw_std[14, 19] -0.261  1.209  1.029\n",
      "def_rw_std[18, 7]   0.114  1.175  1.029\n",
      "def_rw_std[9, 16]  -0.156  1.121  1.028\n",
      "def_rw_std[23, 16]  0.176  1.113  1.028\n",
      "def_rw_std[30, 12]  0.093  1.108  1.028\n",
      "lambda_home[191]    1.557  0.292  1.028\n",
      "\n",
      "=== KEY PARAMETERS ===\n",
      "sigma_att: mean=0.0090, r_hat=1.003\n",
      "sigma_def: mean=0.0080, r_hat=1.009\n",
      "rho_att: mean=0.9810, r_hat=1.005\n",
      "rho_def: mean=0.9530, r_hat=1.016\n",
      "beta_xG: mean=0.1990, r_hat=1.010\n"
     ]
    }
   ],
   "source": [
    "# Final convergence check\n",
    "print(\"=== CONVERGENCE SUMMARY ===\")\n",
    "print(f\"Total parameters with R-hat > 1.01: {(summary['r_hat'] > 1.01).sum()}/{len(summary)}\")\n",
    "print(f\"Total parameters with R-hat > 1.05: {(summary['r_hat'] > 1.05).sum()}/{len(summary)}\")\n",
    "\n",
    "print(\"\\nWorst R-hat values:\")\n",
    "print(summary.nlargest(10, 'r_hat')[['mean', 'sd', 'r_hat']])\n",
    "\n",
    "print(\"\\n=== KEY PARAMETERS ===\")\n",
    "for param in ['sigma_att', 'sigma_def', 'rho_att', 'rho_def', 'beta_xG']:\n",
    "    if param in summary.index:\n",
    "        row = summary.loc[param]\n",
    "        print(f\"{param}: mean={row['mean']:.4f}, r_hat={row['r_hat']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26ee83",
   "metadata": {},
   "source": [
    "# Rolling Window Cross-Validation\n",
    "\n",
    "Evaluate model robustness by training on expanding windows and testing on future rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43a1cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rounds available: 34\n",
      "\n",
      "=== CROSS-VALIDATION WINDOWS ===\n",
      "Window 1: Train rounds 1-25 (281 matches) → Test rounds 26-26 (8 matches)\n",
      "Window 2: Train rounds 1-26 (289 matches) → Test rounds 27-27 (20 matches)\n",
      "Window 3: Train rounds 1-27 (309 matches) → Test rounds 28-28 (10 matches)\n",
      "Window 4: Train rounds 1-28 (319 matches) → Test rounds 29-29 (11 matches)\n",
      "Window 5: Train rounds 1-29 (330 matches) → Test rounds 30-30 (9 matches)\n",
      "Window 6: Train rounds 1-30 (339 matches) → Test rounds 31-31 (11 matches)\n",
      "Window 7: Train rounds 1-31 (350 matches) → Test rounds 32-32 (10 matches)\n",
      "Window 8: Train rounds 1-32 (360 matches) → Test rounds 33-33 (8 matches)\n",
      "Window 9: Train rounds 1-33 (368 matches) → Test rounds 34-34 (12 matches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:34: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(adjust_round)\n",
      "/users/hadiahmed/documents/projects/football-predictor/src/football_model/features/add_metadata.py:36: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('season', group_keys=False).apply(make_rounds_consecutive)\n"
     ]
    }
   ],
   "source": [
    "# Rolling window cross-validation\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "# Configuration\n",
    "min_train_rounds = 25  # Minimum rounds to train on\n",
    "test_window = 1        # Test on next 5 rounds\n",
    "step_size = 1          # Move forward by 5 rounds each time\n",
    "\n",
    "# Get full dataset\n",
    "df_cv = get_understat_data(leagues=['EPL'], years=['2024'])\n",
    "df_cv = add_rounds_to_data(df_cv)\n",
    "df_cv = add_match_ids(df_cv)\n",
    "df_cv = add_home_away_goals_xg(df_cv)\n",
    "\n",
    "max_round = df_cv['cum_round'].max()\n",
    "print(f\"Total rounds available: {max_round}\")\n",
    "\n",
    "# Define windows\n",
    "windows = []\n",
    "current_train_end = min_train_rounds\n",
    "while current_train_end + test_window <= max_round:\n",
    "    test_start = current_train_end + 1\n",
    "    test_end = min(test_start + test_window - 1, max_round)\n",
    "    windows.append({\n",
    "        'train_start': 1,\n",
    "        'train_end': current_train_end,\n",
    "        'test_start': test_start,\n",
    "        'test_end': test_end\n",
    "    })\n",
    "    current_train_end += step_size\n",
    "\n",
    "print(f\"\\n=== CROSS-VALIDATION WINDOWS ===\")\n",
    "for i, w in enumerate(windows, 1):\n",
    "    n_train = len(df_cv[df_cv['cum_round'] <= w['train_end']]) // 2\n",
    "    n_test = len(df_cv[(df_cv['cum_round'] >= w['test_start']) & \n",
    "                       (df_cv['cum_round'] <= w['test_end'])]) // 2\n",
    "    print(f\"Window {i}: Train rounds {w['train_start']}-{w['train_end']} ({n_train} matches) → \"\n",
    "          f\"Test rounds {w['test_start']}-{w['test_end']} ({n_test} matches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "484caa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WINDOW 1/9: Training on rounds 1-25\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274281770de84dabb29ea7f19bf1581a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 170 seconds.\n",
      "There were 341 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 1 Results:\n",
      "  MAE: 0.750\n",
      "  Log Likelihood: -44.54 (vs Naive: -46.80)\n",
      "  Improvement: 2.25\n",
      "\n",
      "============================================================\n",
      "WINDOW 2/9: Training on rounds 1-26\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0950684f82de43c9bb4726b7742fbf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 243 seconds.\n",
      "There were 184 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 2 Results:\n",
      "  MAE: 0.780\n",
      "  Log Likelihood: -106.76 (vs Naive: -109.96)\n",
      "  Improvement: 3.20\n",
      "\n",
      "============================================================\n",
      "WINDOW 3/9: Training on rounds 1-27\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2174192b75964883bb3817d39110da80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 248 seconds.\n",
      "There were 152 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 3 Results:\n",
      "  MAE: 0.906\n",
      "  Log Likelihood: -63.77 (vs Naive: -66.61)\n",
      "  Improvement: 2.84\n",
      "\n",
      "============================================================\n",
      "WINDOW 4/9: Training on rounds 1-28\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94a360c79d44a039c58f8855ba489d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 192 seconds.\n",
      "There were 2426 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Results:\n",
      "  MAE: 1.125\n",
      "  Log Likelihood: -67.87 (vs Naive: -74.22)\n",
      "  Improvement: 6.35\n",
      "\n",
      "============================================================\n",
      "WINDOW 5/9: Training on rounds 1-29\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b32311b52824dabbe574805df242cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 220 seconds.\n",
      "There were 77 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 5 Results:\n",
      "  MAE: 0.610\n",
      "  Log Likelihood: -48.31 (vs Naive: -57.01)\n",
      "  Improvement: 8.70\n",
      "\n",
      "============================================================\n",
      "WINDOW 6/9: Training on rounds 1-30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0fe175c47b490889bd9068d01fc123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 187 seconds.\n",
      "There were 454 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 6 Results:\n",
      "  MAE: 0.929\n",
      "  Log Likelihood: -64.28 (vs Naive: -62.08)\n",
      "  Improvement: -2.21\n",
      "\n",
      "============================================================\n",
      "WINDOW 7/9: Training on rounds 1-31\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6876408d2634685bcbe86cb3e769aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 393 seconds.\n",
      "There were 219 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 7 Results:\n",
      "  MAE: 0.957\n",
      "  Log Likelihood: -58.55 (vs Naive: -56.65)\n",
      "  Improvement: -1.89\n",
      "\n",
      "============================================================\n",
      "WINDOW 8/9: Training on rounds 1-32\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8deb4be2bbb04d8ca1df5f16929702f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 246 seconds.\n",
      "There were 85 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 8 Results:\n",
      "  MAE: 0.826\n",
      "  Log Likelihood: -43.57 (vs Naive: -46.35)\n",
      "  Improvement: 2.78\n",
      "\n",
      "============================================================\n",
      "WINDOW 9/9: Training on rounds 1-33\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [sigma_att, rho_att, sigma_def, rho_def, att_0, def_0, att_rw_std, def_rw_std, home_mu, home_sd, home_adv, beta_xG]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3736937ed6c4d0fbdeff6a2c6d13c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 2_000 tune and 2_000 draw iterations (6_000 + 6_000 draws total) took 238 seconds.\n",
      "There were 708 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 9 Results:\n",
      "  MAE: 0.804\n",
      "  Log Likelihood: -66.13 (vs Naive: -71.17)\n",
      "  Improvement: 5.04\n",
      "\n",
      "============================================================\n",
      "CROSS-VALIDATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation (this will take time!)\n",
    "results = []\n",
    "\n",
    "for i, window in enumerate(windows, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WINDOW {i}/{len(windows)}: Training on rounds {window['train_start']}-{window['train_end']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Prepare training data\n",
    "    train_data = prepare_model_data(df_cv, test_round=window['train_end'])\n",
    "    \n",
    "    # Build and sample model\n",
    "    config = ModelConfig(clip_theta=5.0, center_team_strength=False, use_opponent_adjusted_xG=True,use_xG=True)\n",
    "    model_cv = build_model(train_data, config)\n",
    "    \n",
    "    with model_cv:\n",
    "        trace_cv = pm.sample(\n",
    "            2000,  # Fewer samples for speed\n",
    "            tune=2000,\n",
    "            chains=3,  # Fewer chains for speed\n",
    "            target_accept=0.95,\n",
    "            random_seed=42 + i,\n",
    "            return_inferencedata=True,\n",
    "            discard_tuned_samples=True\n",
    "        )\n",
    "    \n",
    "    # Get posterior means\n",
    "    attack_mean_cv = trace_cv.posterior['attack'].mean(dim=['chain', 'draw']).values\n",
    "    defense_mean_cv = trace_cv.posterior['defence'].mean(dim=['chain', 'draw']).values\n",
    "    home_adv_mean_cv = trace_cv.posterior['home_adv'].mean(dim=['chain', 'draw']).values\n",
    "    beta_xG_mean_cv = trace_cv.posterior['beta_xG'].mean(dim=['chain', 'draw']).values\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_mask_cv = ((df_cv['cum_round'] >= window['test_start']) & \n",
    "                    (df_cv['cum_round'] <= window['test_end'])).values\n",
    "    test_indices_cv = np.where(test_mask_cv)[0]\n",
    "    \n",
    "    # Team mapping\n",
    "    teams_cv = pd.unique(df_cv[['team', 'opp_team']].values.ravel())\n",
    "    team_idx_map_cv = {t: i for i, t in enumerate(teams_cv)}\n",
    "    df_cv[\"team_id\"] = df_cv[\"team\"].map(team_idx_map_cv)\n",
    "    df_cv[\"opp_id\"] = df_cv[\"opp_team\"].map(team_idx_map_cv)\n",
    "    \n",
    "    # Make predictions\n",
    "    last_t_cv = attack_mean_cv.shape[0] - 1\n",
    "    test_lambda_home_cv = []\n",
    "    test_lambda_away_cv = []\n",
    "    \n",
    "    for idx in test_indices_cv:\n",
    "        team_id = int(df_cv.iloc[idx]['team_id'])\n",
    "        opp_id = int(df_cv.iloc[idx]['opp_id'])\n",
    "        is_home = df_cv.iloc[idx]['is_home']\n",
    "        xG_home = df_cv.iloc[idx]['xG_home']\n",
    "        xG_away = df_cv.iloc[idx]['xG_away']\n",
    "        \n",
    "        theta_home = (beta_xG_mean_cv * np.log(xG_home + 0.01) + \n",
    "                      attack_mean_cv[last_t_cv, team_id] - \n",
    "                      defense_mean_cv[last_t_cv, opp_id])\n",
    "        if is_home == 1:\n",
    "            theta_home += home_adv_mean_cv[team_id]\n",
    "        \n",
    "        theta_away = (beta_xG_mean_cv * np.log(xG_away + 0.01) + \n",
    "                      attack_mean_cv[last_t_cv, opp_id] - \n",
    "                      defense_mean_cv[last_t_cv, team_id])\n",
    "        \n",
    "        test_lambda_home_cv.append(np.exp(np.clip(theta_home, -5, 5)))\n",
    "        test_lambda_away_cv.append(np.exp(np.clip(theta_away, -5, 5)))\n",
    "    \n",
    "    test_lambda_home_cv = np.array(test_lambda_home_cv)\n",
    "    test_lambda_away_cv = np.array(test_lambda_away_cv)\n",
    "    test_goals_home_cv = df_cv[test_mask_cv]['goals_home'].values\n",
    "    test_goals_away_cv = df_cv[test_mask_cv]['goals_away'].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae_home_cv = np.mean(np.abs(test_lambda_home_cv - test_goals_home_cv))\n",
    "    mae_away_cv = np.mean(np.abs(test_lambda_away_cv - test_goals_away_cv))\n",
    "    mae_cv = (mae_home_cv + mae_away_cv) / 2\n",
    "    \n",
    "    ll_home_cv = poisson.logpmf(test_goals_home_cv.astype(int), test_lambda_home_cv).sum()\n",
    "    ll_away_cv = poisson.logpmf(test_goals_away_cv.astype(int), test_lambda_away_cv).sum()\n",
    "    ll_total_cv = ll_home_cv + ll_away_cv\n",
    "    \n",
    "    # Naive baseline\n",
    "    naive_lambda = df_cv[df_cv['cum_round'] <= window['train_end']]['goals_home'].mean()\n",
    "    naive_ll_cv = (poisson.logpmf(test_goals_home_cv.astype(int), naive_lambda).sum() +\n",
    "                   poisson.logpmf(test_goals_away_cv.astype(int), naive_lambda).sum())\n",
    "    \n",
    "    results.append({\n",
    "        'window': i,\n",
    "        'train_rounds': f\"{window['train_start']}-{window['train_end']}\",\n",
    "        'test_rounds': f\"{window['test_start']}-{window['test_end']}\",\n",
    "        'n_train': len(train_data.goals_home),\n",
    "        'n_test': len(test_goals_home_cv) + len(test_goals_away_cv),\n",
    "        'mae': mae_cv,\n",
    "        'log_likelihood': ll_total_cv,\n",
    "        'll_naive': naive_ll_cv,\n",
    "        'll_improvement': ll_total_cv - naive_ll_cv,\n",
    "        'beta_xG': beta_xG_mean_cv\n",
    "    })\n",
    "    \n",
    "    print(f\"Window {i} Results:\")\n",
    "    print(f\"  MAE: {mae_cv:.3f}\")\n",
    "    print(f\"  Log Likelihood: {ll_total_cv:.2f} (vs Naive: {naive_ll_cv:.2f})\")\n",
    "    print(f\"  Improvement: {ll_total_cv - naive_ll_cv:.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CROSS-VALIDATION COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650ad255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CROSS-VALIDATION SUMMARY ===\n",
      "\n",
      " window train_rounds test_rounds  n_train  n_test      mae  log_likelihood    ll_naive  ll_improvement            beta_xG\n",
      "      1         1-25       26-26      562      32 0.896210      -50.045064  -46.795610       -3.249455 0.8650217598855807\n",
      "      2         1-26       27-27      578      80 0.658699     -101.039836 -109.964349        8.924513 0.8396239054658629\n",
      "      3         1-27       28-28      618      40 0.731261      -53.626309  -66.613612       12.987303 0.8341806054267192\n",
      "      4         1-28       29-29      638      44 1.059551      -64.342863  -74.219989        9.877126 0.8419215369803251\n",
      "      5         1-29       30-30      660      36 0.630198      -46.831527  -57.006277       10.174749 0.8380414819807616\n",
      "      6         1-30       31-31      678      44 0.648525      -55.748766  -62.075977        6.327211 0.8291160317201468\n",
      "      7         1-31       32-32      700      40 0.727783      -50.019390  -56.653447        6.634057 0.8366354121392339\n",
      "      8         1-32       33-33      720      32 0.755986      -41.492149  -46.351450        4.859301 0.8519154578784857\n",
      "      9         1-33       34-34      736      48 0.779844      -65.697338  -71.170729        5.473392 0.8476607984098968\n",
      "\n",
      "============================================================\n",
      "AVERAGE PERFORMANCE ACROSS ALL WINDOWS\n",
      "============================================================\n",
      "Mean MAE: 0.765 ± 0.137\n",
      "Mean Log Likelihood: -58.76 ± 17.66\n",
      "Mean LL Improvement over Naive: 6.89 ± 4.61\n",
      "Mean beta_xG: 0.843 ± 0.011\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE STABILITY\n",
      "============================================================\n",
      "MAE Range: 0.630 to 1.060\n",
      "LL Improvement Range: -3.25 to 12.99\n",
      "All windows beat naive baseline: False\n"
     ]
    }
   ],
   "source": [
    "# Summarize cross-validation results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n=== CROSS-VALIDATION SUMMARY ===\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AVERAGE PERFORMANCE ACROSS ALL WINDOWS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mean MAE: {results_df['mae'].mean():.3f} ± {results_df['mae'].std():.3f}\")\n",
    "print(f\"Mean Log Likelihood: {results_df['log_likelihood'].mean():.2f} ± {results_df['log_likelihood'].std():.2f}\")\n",
    "print(f\"Mean LL Improvement over Naive: {results_df['ll_improvement'].mean():.2f} ± {results_df['ll_improvement'].std():.2f}\")\n",
    "print(f\"Mean beta_xG: {results_df['beta_xG'].mean():.3f} ± {results_df['beta_xG'].std():.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PERFORMANCE STABILITY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAE Range: {results_df['mae'].min():.3f} to {results_df['mae'].max():.3f}\")\n",
    "print(f\"LL Improvement Range: {results_df['ll_improvement'].min():.2f} to {results_df['ll_improvement'].max():.2f}\")\n",
    "print(f\"All windows beat naive baseline: {(results_df['ll_improvement'] > 0).all()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
